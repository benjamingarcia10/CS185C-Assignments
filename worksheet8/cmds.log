    1  passwd
    2  git clone https://github.com/benjamingarcia10/CS185C-Assignments.git
    3  git pull
    4  cd CS185C-Assignments/
    5  ls
    6  git pull
    7  cd ../
    8  ls
    9  wget http://ftp.gnu.org/gnu/datamash/datamash-1.3.tar.gz
   10  tar -xzf datamash-1.3.tar.gz
   11  cd datamash-1.3
   12  ./configure
   13  make
   14  make check
   15  for file in `ls ../CS185C-Assignments/assignment2/CUSTOMERS/` ; do ./datamash -W ppearson 1:2 < ../CS185C-Assignments/assignment2/CUSTOMERS/$file >> ../CS185C-Assignments/assignment2/correlation.txt; done
   16  cd ../CS185C-Assignments/assignment2
   17  ls
   18  vi correlation.txt 
   19  git status
   20  git add .
   21  mv correlation.txt customers_correlation.txt
   22  git add .
   23  git status
   24  git commit -m "Added correlation from datamash"
   25  git config --global user.email "benjamingarcia10@gmail.com"
   26  git config --global user.name "Benjamin Garcia"
   27  git config --global credential.helper manager
   28  git status
   29  git push
   30  git commit -m "Added correlation from datamash"
   31  git status
   32  git push
   33  git status
   34  git push
   35  ls
   36  perl -pe 's/\x1b\[[0-9;]*[mG]//g' a2.txt > a2.txt.clean
   37  tr -cd '\11\12\15\40-\176' < a2.txt.clean > a2.txt.clean2
   38  sed -i "s///g" a2.txt.clean2
   39  ls
   40  vi a2.txt.clean2
   41  rm a2.txt.clean
   42  mv a2.txt.clean2 a2.txt.clean
   43  git status
   44  git add .
   45  git commit -m "Cleaned script"
   46  git push
   47  git config --global credential.helper store
   48  git push
   49  ls
   50  cd ../../
   51  ls
   52  cd CS185C-Assignments/
   53  ls
   54  git pull
   55  wc customerids.txt.sorted.uniqcount.reversed -l
   56  wc -l customerids.txt.sorted.uniqcount.reversed 
   57  wc -l productids.txt.sorted.uniqcount.reversed 
   58  cd ../
   59  l
   60  tar -xzf amazon_reviews*
   61  gzip -d amazon_reviews_us_Books_v1_02.tsv.gz 
   62  wc -l customerids.txt.sorted.uniqcount.reversed
   63  wc -l ../customerids.txt.sorted.uniqcount.reversed 
   64  mkdir CUSTOMERS
   65  ls
   66  head -n 5 ../customerids.txt.sorted.uniqcount.reversed 
   67  head -n 5 ../productids.txt.sorted.uniqcount.reversed 
   68  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed 
   69  sed '3!d' ../customerids.txt.sorted.uniqcount.reversed 
   70  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk -F '	' '{print $2}'
   71  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'
   72  vi ../customerids.txt.sorted.uniqcount.reversed 
   73  $customerId =  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk -F '    ' '{print $2}'
   74  customerId =  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk -F '    ' '{print $2}'
   75  customerId= sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk -F '    ' '{print $2}'
   76  customer
   77  customerId=`sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk -F '{print $2}'`
   78  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk -F '{print $2}'
   79  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk -F '	' '{print $2}'
   80  sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'
   81  mkdir CUSTOMERS
   82  for i in {1..1000}; do id=$(sed '${i}!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv >> CUSTOMERS/$id.txt; done
   83  ls
   84  ls CUSTOMERS/
   85  for i in {1..1000}; do id=$(sed '$i!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv >> CUSTOMERS/$id.txt; done
   86  ls
   87  ls CUSTOMERS/
   88  mkdir CUSTOMERS
   89  for i in {1..1000}; do id=$(sed '${i}!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv >> CUSTOMERS/$id.txt; done
   90  for i in {1..1000}; do id=$(sed "${i}\!d" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv >> CUSTOMERS/$id.txt; done
   91  for i in {1..1000}; do id=$(sed "$i\!d" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv >> CUSTOMERS/$id.txt; done
   92  ls
   93  script ws5.txt
   94  ls
   95  rm ws5.txt 
   96  ls
   97  rm -r CUSTOMERS/
   98  script ws5.txt
   99  rm ws5.txt 
  100  rm -r CUSTOMERS/
  101  script ws5.txt
  102  rm -r CUSTOMERS/
  103  rm ws5.txt 
  104  for i in {1..1000}; do id=$(sed '$i!d" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; done
  105  for i in {1..1000}; do id=$(sed '1!d" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; done
  106  ;
  107  cd CS185C-Assignments/
  108  mkdir worksheet5
  109  ls
  110  cd ../
  111  ls
  112  cd CS185C-Assignments/worksheet5
  113  ls
  114  script ws5.txt
  115  ls
  116  rm ws5.txt 
  117  tmux
  118  tmux ls
  119  tmux
  120  tmux ls
  121  tmux attach -t 0
  122  ls
  123  mkdir CUSTOMERS
  124  for i in {1..1000}; do id=$(sed -n "${i}p" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv >> CUSTOMERS/$id.txt; done
  125  ls
  126  cd CUSTOMERS
  127  ls -l | wc
  128  ls
  129  vi 31844968.txt 
  130  history > cmds.log
  131  mv cmds.log ../cmds.log
  132  cd ../
  133  vi cmds.log 
  134  cd ../
  135  ls
  136  ls -a
  137  git status
  138  touch .gitignore
  139  vi .gitignore
  140  cd worksheet5
  141  git status
  142  git add .
  143  git status
  144  tmux ls
  145  tmux attach -t 0
  146  ls
  147  head -n 1 amazon_reviews_us_Books_v1_02.tsv 
  148  awk -F "\t" '{print $6}' amazon_reviews_us_Books_v1_02.tsv >> product_titles.txt
  149  ls
  150  vi product_titles.txt 
  151  wc -l product_titles.txt 
  152  vi product_titles.txt 
  153  wc -l product_titles.txt 
  154  sort product_titles.txt 
  155  sort product_titles.txt -u >> product_titles.sorted.duplicatesremoved
  156  wc -l product_titles.sorted.duplicatesremoved 
  157  wc -l CS185C-Assignments/productids.txt.sorted.uniqcount.reversed 
  158  wc -l CS185C-Assignments/customerids.txt.sorted.uniqcount.reversed 
  159  git pull
  160  cd CS185C-Assignments/
  161  git pull
  162  cd assignment5
  163  ls
  164  cd assignment2
  165  ls
  166  rm a2.txt
  167  mv a2.txt.clean a2.txt
  168  git add .
  169  git commit -m "Renamed clean a2 script"
  170  git push
  171  ls
  172  rm -i test.txt 
  173  ls
  174  cd CS185C-Assignments/
  175  ls ..
  176  ls -a
  177  pwd
  178  ls ..
  179  vi /.bashrc
  180  cd ../
  181  ls
  182  vi .bashrc 
  183  ls
  184  cd CS185C-Assignments/
  185  cd ../
  186  more product_titles.sorted.duplicatesremoved 
  187  more product_titles.sorted.duplicatesremoved -p
  188  more -p product_titles.sorted.duplicatesremoved 
  189  more page product_titles.sorted.duplicatesremoved 
  190  more product_titles.sorted.duplicatesremoved 
  191  more -p product_titles.sorted.duplicatesremoved 
  192  clear
  193  more product_titles.sorted.duplicatesremoved 
  194  clear
  195  more -p product_titles.sorted.duplicatesremoved 
  196  ls -altr
  197  more -p product_titles.sorted.duplicatesremoved 
  198  vi product_titles.sorted.duplicatesremoved 
  199  vim product_titles.s
  200  vim product_titles.sorted.duplicatesremoved 
  201  vi product_titles.sorted.duplicatesremoved 
  202  cd CS185C-Assignments/assignment2
  203  ls
  204  cd /
  205  ls
  206  ls usr
  207  cd home/
  208  ls
  209  cd garcia
  210  ls
  211  vi product_titles.sorted.duplicatesremoved 
  212  display
  213  ls [A-Z]
  214  display [AZ]
  215  ls A...Z
  216  ls A ... Z
  217  ls [AZ]
  218  ls [A-Z]
  219  ls
  220  wc -l product_titles.sorted.duplicatesremoved | tee outfile
  221  ls
  222  vi outfile 
  223  rm outfile 
  224  echo $HOME
  225  vi product_titles.sorted.duplicatesremoved 
  226  echo $home
  227  echo $HOME
  228  echo HOME
  229  echo " \"UNIX\" "
  230  echo "\"UNIX\""
  231  ls -altr
  232  vi test2.txt 
  233  grep test2.txt product_titles.txt "UNIX"
  234  grep UNIX File?
  235  touch File1
  236  vi File1
  237  cp File1 File2
  238  cp File1 File3
  239  grep UNIX File?
  240  ls ??
  241  cat File1 File2 newfile
  242  cat File1 File2 >> newfile
  243  vi newfile 
  244  ls
  245  vi q
  246  cat q > a
  247  cat q > b
  248  cat q > c
  249  cat q > d
  250  find . -type f -name "?" -print
  251  find . -type f -name '?' -print
  252  find . -type f -name '\?' -print
  253  cat q > ?
  254  ls -i
  255  mv a newfilename.txt
  256  ls -i
  257  vi test2.txt 
  258  ls
  259  rm File? ?
  260  ls
  261  rm newfile
  262  rm test2.txt
  263  ls
  264  rm newfilename.txt 
  265  ls
  266  cd ../worksheet4
  267  export DATETIME=`date "+%Y%m%d_%H%M%S"`
  268  echo $DATETIME 
  269  ls
  270  cd PRODUCTS/
  271  ls
  272  cp 0439139597.txt 0439139597.$DATETIME.txt
  273  ls
  274  head -n 1 0439139597.20211013_002048.txt 
  275  head -n 1 ../../../amazon_reviews_us_Books_v1_02.tsv 
  276  vi 0439139597.20211013_002048.txt 
  277  tail -n 1 0439139597.20211013_002048.txt 
  278  crontab -l
  279  ln -s 0439139597.20211013_002048.txt 0439139597.LATEST.txt
  280  ls
  281  ls -altri
  282  ls -i
  283  tail -n 1 0439139597.LATEST.txt 
  284  cd ../../worksheet6
  285  vi rating_score.cron
  286  cd ~/CS185C-Assignments/worksheet4/PRODUCTS
  287  cd ../../worksheet6
  288  ls
  289  vi rating_score.cron 
  290  crontab rating_score.cron 
  291  crontab -l
  292  cd ~/CS185C-Assignments/worksheet4/PRODUCTS
  293  ls
  294  less 0439139597.AVGRATING.txt 
  295  total=0; count=0; for i in `cut -f 2 ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.LATEST.txt`; do total=$(echo $total+$i | bc); ((count ++)); done; echo "scale=2; $total/$count" | bc
  296  vi *.AVGRATING*
  297  cd ../../worksheet4
  298  cd ../worksheet6
  299  ls
  300  crontab -r
  301  vi rating_score.cron 
  302  total=0; count=0; for i in `cut -f 8 ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.LATEST.txt`; do total=$(echo $total+$i | bc); ((count ++)); done; echo "scale=2; $total/$count" | bc > ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.AVGRATING.txt 2>&1
  303  cd ../worksheet4
  304  cd PRODUCTS/
  305  ls
  306  vi 0439139597.AVGRATING.txt 
  307  rm 0439139597.AVGRATING.txt 
  308  cd ../../worksheet6
  309  ls
  310  crontab rating_score.cron 
  311  crontab -l
  312  cd ../worksheet4/PRODUCTS/
  313  ls
  314  vi 0439139597.AVGRATING.txt 
  315  cd ../../worksheet6
  316  crontab -l
  317  crontab -r
  318  vi *.cron
  319  crontab rating_score.cron 
  320  crontab -l
  321  cd ../worksheet4
  322  cd P*
  323  ls
  324  rm 0439139597.AVGRATING.txt 
  325  ls
  326  vi *.AVGRATING*
  327  crontab -r
  328  cd ../../worksheet6
  329  * * * * * awk '{ sum += $8 } END { if (NR > 0) print sum /NR }' ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.LATEST.txt >> ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.AVGRATING.txt 2>&1
  330  awk '{ sum += $8 } END { if (NR > 0) print sum /NR }' ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.LATEST.txt t
  331  awk '{ sum += $8 } END { if (NR > 0) print sum /NR }' ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.LATEST.txt
  332  awk -F "	" '{ sum += $8 } END { if (NR > 0) print sum /NR }' ~/CS185C-Assignments/worksheet4/PRODUCTS/0439139597.LATEST.txt
  333  vi rating_score.cron 
  334  crontab -l
  335  crontab rating_score.cron 
  336  cd ../worksheet4/PRODUCTS/
  337  ls
  338  rm *.AVG
  339  rm *.AVG*
  340  ls
  341  vi 0439139597.AVGRATING.txt 
  342  cd ../../worksheet6
  343  history > cmds.log
  344  cd CS185C-Assignments/
  345  ls
  346  cd worksheet4
  347  ls
  348  cd PRODUCTS/
  349  ls
  350  head -n 2 0439139597.txt 
  351  cd ../
  352  ls
  353  cd../
  354  cd ../
  355  ls
  356  ls worksheet1
  357  ls worksheet2
  358  ls worksheet3
  359  ls worksheet4
  360  ls worksheet5
  361  ls worksheet5/CUSTOMERS
  362  clear
  363  ls
  364  ls assignment2
  365  ls assignment2/CUSTOMERS
  366  clear
  367  mkdir worksheet6
  368  cd worksheet6
  369  script ws6.txt
  370  git status
  371  vi ../worksheet4/PRODUCTS/0439139597.AVGRATING.txt 
  372  crontab -r
  373  git add .
  374  git status
  375  cd ../
  376  git add .
  377  git status
  378  git commit -m "Worksheet 6 files"
  379  git push
  380  cd ../worksheet4/PRODUCTS/
  381  cp 0439139597.txt ../../worksheet7/0439139597.txt
  382  cd ../../worksheet7
  383  ls
  384  head -n 1 ../../amazon_reviews_us_Books_v1_02.tsv 
  385  cut -d "	" -f 14 0439139597.txt > 0439139597.REVIEWBODY.txt 
  386  head -n 5 0439139597.REVIEWBODY.txt 
  387  head -n 2 0439139597.txt 
  388  sed -i -e 's/[\.,;]//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/it//g'
  389  head -n 5 0439139597.REVIEWBODY.txt 
  390  sed -i 's/<.*\/>//g' 0439139597.REVIEWBODY.txt 
  391  head -n 5 0439139597.REVIEWBODY.txt 
  392  cut -d "	" -f 14 0439139597.txt > 0439139597.REVIEWBODY.txt 
  393  head -n 5 0439139597.REVIEWBODY.txt 
  394  sed -i -e 's/[\.,;]//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/it//g' 0439139597.REVIEWBODY.txt 
  395  sed -i 's/<.*?\/>//g' 0439139597.REVIEWBODY.txt 
  396  head -n 5 0439139597.REVIEWBODY.txt 
  397  sed -i 's/<.*?\/>//g' 0439139597.REVIEWBODY.txt 
  398  head -n 5 0439139597.REVIEWBODY.txt 
  399  sed -i 's/<[^/]*\/>//g' 0439139597.REVIEWBODY.txt 
  400  head -n 5 0439139597.REVIEWBODY.txt 
  401  history > cmds.log
  402  cd CS185C-Assignments/
  403  ls
  404  mkdir worksheet7
  405  cd worksheet4
  406  ls
  407  cd PRODUCTS/
  408  ls
  409  cd ../../worksheet7
  410  script ws7.txt
  411  git status
  412  git add .
  413  git status
  414  git commit -m "Worksheet 7 files"
  415  git push
  416  git rm 0439139597.txt 
  417  ls
  418  git status
  419  git commit -m "Delete unneccessary duplicate"
  420  git status
  421  git push
  422  ls
  423  cd CS185C-Assignments/
  424  ls
  425  mkdir assignment3
  426  cd assignment3
  427  tmux new-session -s a3
  428  ls ../assignment2
  429  script a3.txt
  430  ls ../assignment2/PRODUCTS/
  431  head -n 3 ../assignment2/PRODUCTS/0060193395.txt 
  432  vi ../assignment2/PRODUCTS/0060193395.txt 
  433  head -n 1 ../../amazon_reviews_us_Books_v1_02.tsv 
  434  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS`; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/CS185C-Assignments/assignment2/PRODUCTS/$customerID.TOTAL.txt; fi; done
  435  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS` ; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/CS185C-Assignments/assignment2/PRODUCTS/$customerID.TOTAL.txt; fi; done
  436  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS`; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;'`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/CS185C-Assignments/assignment2/PRODUCTS/$customerID.TOTAL.txt; fi; done
  437  ls ../assignment2/PRODUCTS/
  438  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS`; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;'`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/CS185C-Assignments/assignment2/PRODUCTS/$customerID.TOTAL.txt; echo "Customer ID: $customerID"; fi; done
  439  vi ../assignment2/PRODUCTS/0060193395.TOTAL.txt 
  440  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS`; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;'`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/CS185C-Assignments/assignment2/PRODUCTS/$customerID.TOTAL.txt; echo "Customer ID: $customerID"; fi; done
  441  ls ../assignment2/CUSTOMERS/
  442  ls ../assignment2/PRODUCTS/
  443  head -n 5 ../assignment2/PRODUCTS/0060193395.TOTAL.txt 
  444  head -n 5 ../assignment2/PRODUCTS/0060193395.txt 
  445  count=0; for file in `ls ~/CS185C-Assignments/assignment2/CUSTOMERS`; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;'`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/CS185C-Assignments/assignment2/CUSTOMERS/$customerID.TOTAL.txt; echo "Customer ID: $customerID, Count: $count"; (( count++ )); fi; done
  446  head -n 5 ../assignment2/CUSTOMERS/53084107.TOTAL.txt 
  447  head -n 5 ../assignment2/CUSTOMERS/53084107.txt 
  448  tail -n 5 ../assignment2/CUSTOMERS/53084107.TOTAL.txt 
  449  tail -n 5 ../assignment2/CUSTOMERS/53084107.txt 
  450  for file in `ls ~/CS185C-Assignments/assignment2/CUSTOMERS` ; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d'`; if [ ! -z "$customerID" ]; then median=`cut -f 4 ~/CS185C-Assignments/assignment2/CUSTOMERS/$customerID.TOTAL.txt | sort -n | awk ' { a[i++]=$1; } END { x=int((i+1)/2); if (x < (i+1)/2) print (a[x-1]+a[x])/2; else print a[x-1]; }'`; echo -e "$customerID\t$median" >> customer_median.txt; fi; done
  451  ls
  452  vi customer_median.txt 
  453  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS` ; do productID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d'`; if [ ! -z "$productID" ]; then median=`cut -f 4 ~/CS185C-Assignments/assignment2/PRODUCTS/$productID.TOTAL.txt | sort -n | awk ' { a[i++]=$1; } END { x=int((i+1)/2); if (x < (i+1)/2) print (a[x-1]+a[x])/2; else print a[x-1]; }'`; echo -e "$productID\t$median" >> product_median.txt; fi; done
  454  vi product_median.txt
  455  for file in `ls ~/CS185C-Assignments/assignment2/CUSTOMERS` ; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d'`; if [ ! -z "$customerID" ]; then median=`grep $customerID ~/CS185C-Assignments/assignment3/customer_median.txt | cut -f 2`; awk -F '\t' -v median="$median" '{if ($4 < median) print 0, $2; else print 1, $2}' OFS='\t' ~/CS185C-Assignments/assignment2/CUSTOMERS/$customerID.TOTAL.txt > ~/CS185C-Assignments/assignment2/CUSTOMERS/$customerID.BINARY.txt; fi; done
  456  ls ../assignment2/CUSTOMERS
  457  head -n 10 ../assignment2/CUSTOMERS/20595117.TOTAL.txt 
  458  head -n 10 ../assignment2/CUSTOMERS/20595117.BINARY.txt 
  459  head -n 10 ../assignment2/CUSTOMERS/41012519.TOTAL.txt
  460  head -n 10 ../assignment2/CUSTOMERS/41012519.BINARY.txt
  461  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS` ; do productID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d'`; if [ ! -z "$productID" ]; then median=`grep $productID ~/CS185C-Assignments/assignment3/product_median.txt | cut -f 2` ;awk -F '\t' -v median="$median" '{if ($4 < median) print 0, $2; else print 1, $2}' OFS='\t' ~/CS185C-Assignments/assignment2/PRODUCTS/$productID.TOTAL.txt > ~/CS185C-Assignments/assignment2/PRODUCTS/$productID.BINARY.txt; fi; done
  462  ls ../assignment2/PRODUCTS/
  463  head -n 10 ../assignment2/PRODUCTS/0060193395.TOTAL.txt
  464  head -n 10 ../assignment2/PRODUCTS/0060193395.BINARY.txt
  465  grep 0060193395 product_median.txt 
  466  cd $HOME
  467  ls
  468  cd datamash-1.3/
  469  id=$(sed '1!d" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}')
  470  ls
  471  id=$(sed '1!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}')
  472  $id
  473  line=2
  474  id=$(sed '$line!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}')
  475  id=$(sed "${line}\!d' ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}')
  476  id=$(sed "${line}\!d" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}')
  477  id=$(sed "\${line}\!d" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}')
  478  $line
  479  echo $line
  480  echo "${line}\d"
  481  echo "${line}\!d"
  482  echo "${line}\\!d"
  483  echo "${line}\\\!d"
  484  echo "${line}p"
  485  for i in {1..1000}; do id=$(sed -n "${i}p" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv >> CUSTOMERS/$id.txt; done
  486  ls
  487  for i in {1..1000}; do id=$(sed -n "${i}p" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; grep $id ../../amazon_reviews_us_Books_v1_02.tsv; done
  488  for i in {1..1000}; do id=$(sed -n "${i}p" ../customerids.txt.sorted.uniqcount.reversed | awk '{print $2}'); echo $id; done
  489  head -n 10 ../customerids.txt.sorted.uniqcount.reversed 
  490  script ws5.txt
  491  git status
  492  git add .
  493  cd ../
  494  git add .
  495  git status
  496  git commit -m "Worksheet 5 files"
  497  git push
  498  tmux -ls
  499  tmux ls
  500  cd ../../
  501  cd datamash-1.3/
  502  for file in `ls ~/CS185C-Assignments/assignment2/CUSTOMERS` ; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d'`; if [ ! -z "$customerID" ]; then correlation=`./datamash -W ppearson 1:2 < ~/CS185C-Assignments/assignment2/CUSTOMERS/$customerID.BINARY.txt`; echo -e "$customerID\t$correlation" >> ~/CS185C-Assignments/assignment3/customer_correlation.txt; fi; done
  503  for file in `ls ~/CS185C-Assignments/assignment2/PRODUCTS` ; do productID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d'`; if [ ! -z "$productID" ]; then correlation=`./datamash -W ppearson 1:2 < ~/CS185C-Assignments/assignment2/PRODUCTS/$productID.BINARY.txt`; echo -e "$productID\t$correlation" >> ~/CS185C-Assignments/assignment3/product_correlation.txt; fi; done
  504  cd ../CS185C-Assignments/assignment3
  505  ls
  506  vi customer_correlation.txt 
  507  which gnuplot
  508  gnuplot --version
  509  apt-get install gnuplot
  510  sort -k 2 -r product_correlation.txt > product_correlation.sorted.txt
  511  sort -k 2 -r customer_correlation.txt > customer_correlation.sorted.txt
  512  head -n 3 product_correlation.sorted.txt 
  513  head -n 3 customer_correlation.sorted.txt 
  514  head -n 10 product_correlation.sorted.txt 
  515  vi product_correlation.sorted.txt 
  516  head -n 1 ../../amazon_reviews_us_Books_v1_02.tsv 
  517  ls ../assignment2/PRODUCTS/
  518  wc -l ../assignment2/PRODUCTS/0060193395.txt
  519  grep 0060193395 ../../amazon_reviews_us_Books_v1_02.tsv | cut -f 9,14 > 0060193395.REVIEWBODY.txt
  520  ls
  521  head -n 3 0060193395.REVIEWBODY.txt 
  522  sed -i 's/<[^/]*\/>//g' 0060193395.REVIEWBODY.txt 
  523  head -n 3 0060193395.REVIEWBODY.txt 
  524  sl
  525  ls
  526  sed -i 's/\\b[a-zA-Z]{1,2}\\b//g' 0060193395.REVIEWBODY.txt 
  527  head -n 3 0060193395.REVIEWBODY.txt 
  528  sed -i 's/\\b[a-zA-Z]\{1,2\}\\b//g' 0060193395.REVIEWBODY.txt 
  529  head -n 3 0060193395.REVIEWBODY.txt 
  530  sed -i 's/\b[a-zA-Z]\{1,2\}\b//g' 0060193395.REVIEWBODY.txt 
  531  head -n 3 0060193395.REVIEWBODY.txt 
  532  sed -i -e 's/[\.,;]//g' -e 's/and//g' -e 's/or//g' -e 's/if//g' -e 's/in//g' -e 's/it//g' 0060193395.REVIEWBODY.txt 
  533  head -n 3 0060193395.REVIEWBODY.txt 
  534  grep 0060193395 ../../amazon_reviews_us_Books_v1_02.tsv | cut -f 9,14 > 0060193395.REVIEWBODY.txt
  535  sed -i 's/\b[a-zA-Z]\{1,2\}\b//g' 0060193395.REVIEWBODY.txt
  536  sed -i -e 's/[\.,;]//g' -e 's/\band\b//g' -e 's/\bor\b//g' -e 's/\bif\b//g' -e 's/\bin\b//g' -e 's/\bit\b//g' 0060193395.REVIEWBODY.txt
  537  head -n 3 0060193395.REVIEWBODY.txt 
  538  sed -i 's/<[^/]*\/>//g' 0060193395.REVIEWBODY.txt 
  539  head -n 3 0060193395.REVIEWBODY.txt 
  540  awk -F '\t' '{if($1==1) print $2}' OFS=' ' 0060193395.REVIEWBODY.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
  541  awk -F '\t' '{if($1==0) print $2}' OFS=' ' 0060193395.REVIEWBODY.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
  542  cd../../
  543  cd ../../
  544  wget https://downloads.sourceforge.net/project/gnuplot/gnuplot/5.4.2/gnuplot-5.4.2.tar.gz?ts=gAAAAABhb2l0dXgv3mL9Doi0tyn1rT1KwzV3htvxak88GUbj94vNj2dXRfHzz9HTkY9vmqCkb-DPj0iv3crjHf3TVn8iebDdcw%3D%3D&r=
  545  ls
  546  rm *gnuplot*
  547  ls
  548  wget 
  549  wget http://sourceforge.net/projects/gnuplot/files/gnuplot/5.4.2/gnuplot-5.4.2.tar.gz/download
  550  ls
  551  cd download
  552  ls
  553  wget https://downloads.sourceforge.net/project/gnuplot/gnuplot/5.4.2/gnuplot-5.4.2.tar.gz
  554  ls
  555  rm download
  556  ls
  557  tar xvzf gnuplot-5.4.2.tar.gz 
  558  ls
  559  cd gnuplot-5.4.2/
  560  ls
  561  ./configure
  562  make
  563  make install
  564  ls
  565  make check
  566  ls
  567  ls ../datamash-1.3
  568  ./gnuplot
  569  ../datamash-1.3/datamash
  570  gnuplot
  571  ./gnuplot
  572  cd ../
  573  ls
  574  cd CS185C-Assignments/
  575  git status
  576  git add .
  577  cd CS185C-Assignments/
  578  ls
  579  cd assignment3
  580  ls
  581  tail -n 5 a3.txt
  582  clear
  583  vi a3.txt 
  584  cd ../../
  585  ls
  586  cd CS185C-Assignments/assignment3
  587  ls
  588  script a3-1.txt
  589  git add .
  590  git status
  591  git commit -m "Assignment 3 files"
  592  git push
  593  git pull
  594  git status
  595  git push
  596  history | tail -n 50
  597  history
  598  awk -F '\t' '{if($1==1) print $2}' OFS=' ' 0060193395.REVIEWBODY.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
  599  awk -F '\t' '{if($1==0) print $2}' OFS=' ' 0060193395.REVIEWBODY.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
  600  git pull
  601  git status
  602  git rm a3-1.txt 
  603  git status
  604  git add .
  605  git commit -m "Remove extra script file"
  606  git push
  607  sudo apt-get gnuplot
  608  cd CS185C-Assignments/
  609  ls
  610  head -n 5 assignment2/CUSTOMERS/53071109.BINARY.txt 
  611  head -n 10 assignment2/CUSTOMERS/53071109.BINARY.txt 
  612  cd CS185C-Assignments/
  613  ls
  614  ls assignment3
  615  ls assignment2
  616  ls assignment2/PRODUCTS/
  617  head -n 5 assignment2/PRODUCTS/0060392452.BINARY.txt 
  618  vi verified_script.txt 
  619  awk -F "\t" -f verified_script.txt ../../amazon_reviews_us_Books_v1_02.tsv 
  620  ls
  621  wc -l verified.txt 
  622  wc -l unverified.txt 
  623  wc -l verified.txt 
  624  wc -l ../../amazon_reviews_us_Books_v1_02.tsv 
  625  ls
  626  awk -F "\t" "{ print $14 }" verified.txt > verified.reviewbody.txt
  627  head -n 1 verified.txt 
  628  head -n 1 verified.reviewbody.txt 
  629  head -n 3 verified.reviewbody.txt 
  630  awk -F "\t" '{ print $14 }' verified.txt > verified.reviewbody.txt
  631  head -n 3 verified.reviewbody.txt 
  632  head -n 3 verified.txt 
  633  awk -F "\t" '{ print $14 }' unverified.txt > unverified.reviewbody.txt
  634  head -n 100 verified.reviewbody.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r > verified.100reviewbody.freqwords.txt
  635  ls
  636  head -n 10 verified.100reviewbody.freqwords.txt 
  637  head -n 100 unverified.reviewbody.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r > unverified.100reviewbody.freqwords.txt
  638  head -n 10 unverified.100reviewbody.freqwords.txt 
  639  git status
  640  history > cmds.log
